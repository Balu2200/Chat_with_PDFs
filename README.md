# Chat with MultiPDFs

This is a Streamlit application that allows users to upload multiple PDF documents, process them, and ask questions about their content using a conversational AI powered by Google Gemini and FAISS for vector-based search.

## Features
- Upload multiple PDF files.
- Extract text from PDFs and split it into manageable chunks.
- Create a vector store using FAISS and HuggingFace embeddings for efficient document retrieval.
- Interact with the documents by asking questions, with responses generated by the Gemini 1.5 Pro model.
- Maintains a chat history to provide context for follow-up questions.
- Responsive UI with a sidebar for document uploads and a main panel for chat interaction.

## Prerequisites
- Python 3.8 or higher
- A Google Gemini API key (set in a `.env` file as `GEMINI_API_KEY`)
- Required Python packages (listed in `requirements.txt`)

## Installation
1. Clone this repository:
   ```bash
   git clone <repository-url>
   cd <repository-directory>
   ```

2. Create a virtual environment and activate it:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Create a `.env` file in the project root and add your Gemini API key:
   ```
   GEMINI_API_KEY=your_gemini_api_key_here
   ```

## Usage
1. Run the Streamlit app:
   ```bash
   streamlit run app.py
   ```

2. Open your browser and navigate to the provided local URL (usually `http://localhost:8501`).

3. In the sidebar, upload one or more PDF files and click the "Process" button.

4. Once processing is complete, enter your question in the text input field in the main panel to start chatting with your documents.

## Project Structure
- `app.py`: Main application script containing the Streamlit app logic.
- `htmlTemplate.py`: Contains HTML templates (`css`, `bot_template`, `user_template`) for styling the chat interface.
- `.env`: Environment file for storing the Gemini API key (not included in the repository).
- `requirements.txt`: List of Python dependencies.

## Dependencies
Key libraries used in the project:
- `streamlit`: For building the web interface.
- `PyPDF2`: For extracting text from PDF files.
- `langchain`: For text splitting, embeddings, and vector store creation.
- `google-generativeai`: For interacting with the Gemini API.
- `faiss-cpu`: For efficient vector search.
- `python-dotenv`: For loading environment variables.
- `sentence-transformers`: For generating text embeddings.

Install them using:
```bash
pip install streamlit PyPDF2 langchain google-generativeai faiss-cpu python-dotenv sentence-transformers
```

## Notes
- Ensure your Gemini API key is valid and has sufficient quota for usage.
- The application uses the `sentence-transformers/all-MiniLM-L6-v2` model for embeddings, which is lightweight and efficient.
- The FAISS vector store is stored in memory during the session and is reset when the app restarts.
- The chat history is maintained in the Streamlit session state for the duration of the session.

## Troubleshooting
- **PDF Processing Fails**: Ensure the uploaded PDFs are not corrupted and contain extractable text.
- **API Errors**: Verify that the Gemini API key is correctly set in the `.env` file and that your account has access to the Gemini 1.5 Pro model.
- **Memory Issues**: If processing large PDFs, consider increasing the chunk size or using a more powerful machine.

## License
This project is licensed under the MIT License. See the `LICENSE` file for details.

## Acknowledgments
- Built with [Streamlit](https://streamlit.io/) and [LangChain](https://langchain.com/).
- Powered by [Google Gemini](https://ai.google.dev/) and [HuggingFace](https://huggingface.co/).
